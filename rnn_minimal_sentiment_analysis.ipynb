{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔁 Simple RNN Walkthrough for Sentiment Analysis\n",
    "This notebook shows step-by-step how an RNN processes a sentence word by word using manual matrix calculations to update hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Vocabulary and Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple vocabulary and input sentence\n",
    "vocab = {\"i\": 0, \"love\": 1, \"this\": 2, \"movie\": 3}\n",
    "sentence = [\"i\", \"love\", \"this\", \"movie\"]\n",
    "indices = torch.tensor([vocab[word] for word in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually created word embeddings (embedding_dim = 4)\n",
    "embedding_matrix = torch.tensor([\n",
    "    [0.1, 0.2, 0.3, 0.4],   # i\n",
    "    [0.5, 0.6, 0.7, 0.8],   # love\n",
    "    [0.2, 0.1, 0.0, -0.1],  # this\n",
    "    [0.0, 0.1, 0.2, 0.3],   # movie\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define a Simple Manual RNN Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RNN cell with fixed weights\n",
    "class RNNCell:\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        self.Wx = torch.tensor([\n",
    "            [0.1, 0.2, 0.3],\n",
    "            [0.0, -0.1, 0.2],\n",
    "            [0.2, 0.1, 0.0],\n",
    "            [-0.1, 0.1, 0.1]\n",
    "        ])  # shape: (input_dim, hidden_dim)\n",
    "\n",
    "        self.Wh = torch.tensor([\n",
    "            [0.1, 0.0, 0.1],\n",
    "            [0.2, 0.1, -0.1],\n",
    "            [-0.1, 0.2, 0.0]\n",
    "        ])  # shape: (hidden_dim, hidden_dim)\n",
    "\n",
    "        self.b = torch.zeros(3)\n",
    "\n",
    "    def step(self, x_t, h_prev):\n",
    "        return torch.tanh(x_t @ self.Wx + h_prev @ self.Wh + self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the RNN Over the Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Step | x_t (Embedding)            | h_t (Hidden State)\n",
      "-------------------------------------------------------------\n",
      "        0 |     [0.1 0.2 0.3 0.4]     | [0.029991   0.06988589 0.10955847]\n",
      "        1 |     [0.5 0.6 0.7 0.8]     | [0.11550264 0.21546964 0.33283275]\n",
      "        2 |   [ 0.2  0.1  0.  -0.1]   | [0.05131581 0.10769425 0.0599314 ]\n",
      "        3 |     [0.  0.1 0.2 0.3]     | [0.03066767 0.06267345 0.04433308]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and initialize hidden state\n",
    "rnn = RNNCell(input_dim=4, hidden_dim=3)\n",
    "h_t = torch.zeros(3)\n",
    "\n",
    "print(\"Time Step | x_t (Embedding)            | h_t (Hidden State)\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "for idx in indices:\n",
    "    x_t = embedding_matrix[idx]\n",
    "    h_t = rnn.step(x_t, h_t)\n",
    "    x_t_str = str(x_t.numpy())\n",
    "    h_t_str = str(h_t.detach().numpy())\n",
    "    print(f\"{idx.item():>9} | {x_t_str:^25} | {h_t_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "650895cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment score: 0.0320\n",
      "Predicted sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "# 5. Simple Sentiment Analysis Output Layer\n",
    "\n",
    "# Let's assume a simple linear layer to map the final hidden state to a sentiment score\n",
    "# We'll use 1 neuron: positive if >0, negative if <0\n",
    "\n",
    "# W_out is a parameter of the output layer, not produced by the loop above.\n",
    "# The loop above computes h_t (the final hidden state), which is then used here.\n",
    "# There are 3 weights in W_out because the hidden state h_t has dimension 3 (hidden_dim=3).\n",
    "# Each element of h_t is multiplied by its corresponding weight in W_out to compute the sentiment score.\n",
    "W_out = torch.tensor([0.5, -0.3, 0.8])  # shape: (hidden_dim,)\n",
    "b_out = torch.tensor(0.0)\n",
    "\n",
    "# Compute sentiment score from the last hidden state\n",
    "sentiment_score = (h_t * W_out).sum() + b_out\n",
    "\n",
    "# Interpret the result\n",
    "sentiment = \"positive\" if sentiment_score.item() > 0 else \"negative\"\n",
    "\n",
    "print(f\"\\nSentiment score: {sentiment_score.item():.4f}\")\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
